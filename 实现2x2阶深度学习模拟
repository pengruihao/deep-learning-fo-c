#include <stdio.h>
#include <string.h>
#define NUM 6 //训练样本个数
#define INPUT_NUM 2//特征数
#define HIDDEN_LAYER_NUM 2 //隐藏层个数
#define ABS(x) (x > 0 ? x : -x)
#define MAX(a, b) (a > b ? a : b)
//     ⚪ →→→→⚪  
//       ╲    ╱ ╲
//        ╲  ╱	 ╲
//    		 ╲      ⚪ 
//        ╱  ╲	 ╱	
//       ╱		╲	╱	
//     ⚪→→→→→⚪   
// 一个简单的模拟2阶深度学习的模拟，采用梯度下降方法              
void main()
{
	int i = 0, j = 0, m = 0, n = 22223;
	float input[INPUT_NUM][NUM] = {{1,2,10,4,5,6},
								   {2,2,3,4,1,3}};
	float output[NUM] = {41,48,114,82,59,86};
	float learning_speed = 0.001;//学习速率
	float w1[INPUT_NUM][HIDDEN_LAYER_NUM] = {{1,1},
											 {1,1}};
	float w2[HIDDEN_LAYER_NUM] = {1,1};
	float a[HIDDEN_LAYER_NUM] = {0};
	float b1[HIDDEN_LAYER_NUM] = {0,0};
	float b2 = 1;
	float Dw1[INPUT_NUM][HIDDEN_LAYER_NUM] = {0};
	float Dw2[HIDDEN_LAYER_NUM] = {0};
	float Db1[HIDDEN_LAYER_NUM] = {0};
	float Db2 = 0;
	float error = 0;
	float x = 0,y = 0;
	float max = 0;
	while(n)
	{
		max = 0;
		error = 0;
		memset(Dw1,0,sizeof(Dw1));
		memset(Db1,0,sizeof(Db1));
		memset(Dw2,0,sizeof(Dw2));
		Db2 = 0;
		for(i = 0; i < NUM; i++)
		{
			/*计算函数损失函数为y=wx+b，没有激励函数*/
			y = 0;
			for(m = 0; m < HIDDEN_LAYER_NUM; m++)
			{
				a[m] = 0;
				for(j = 0; j < INPUT_NUM; j++)
				{
					a[m] += input[j][i] * w1[j][m];
				}
				a[m] += b1[m];
				y += a[m] * w2[m];
			}
			y += b2;		
			error += (output[i] - y) * (output[i] - y);
			/*计算函数损失函数为y=wx+b，没有激励函数*/
			
			/*计算各个偏导*/
			for(m = 0; m < HIDDEN_LAYER_NUM; m++)
			{
				for(j = 0; j < INPUT_NUM; j++)
				{
					Dw1[j][m] += input[j][i] * w2[m] * (y - output[i]) / NUM;
				}
				Dw2[m] += a[m] * (y - output[i]) / NUM;
				Db1[m] += w2[m] * (y - output[i]) / NUM;
			}
			Db2 += (y - output[i]) / NUM;
			/*计算各个偏导*/
			
		}
		
		/*获取最大偏导数*/
		for(m = 0; m < HIDDEN_LAYER_NUM; m++)
		{
			for(j = 0; j < INPUT_NUM; j++)
			{	
				max = MAX(ABS(Dw1[j][m]), max);
			}
			max = MAX(ABS(Dw2[m]), max);
			max = MAX(ABS(Db1[m]), max);
		}
		max = MAX(ABS(Db2), max);
		/*获取最大偏导数*/
		
		/*获取对w或者b进行更新*/
		for(m = 0; m < HIDDEN_LAYER_NUM; m++)
		{
			for(j = 0; j < INPUT_NUM; j++)
			{
				if(max == ABS(Dw1[j][m]))
				{
					w1[j][m] = w1[j][m] - learning_speed * Dw1[j][m];
				}
			}
			if(max == ABS(Dw2[m]))
			{
				w2[m] = w2[m] - learning_speed * Dw2[m];
			}
			if(max == ABS(Db1[m]))
			{
				b1[m] = b1[m] - learning_speed * Db1[m];
			}
		}
		if(max == ABS(Db2))
		{
			b2 = b2 - learning_speed * Db2;
		}
		/*获取对w或者b进行更新*/		
		n--;
	
	}
	error/=(2 * NUM);
	printf("error %f\n",error);
	for(m = 0; m < HIDDEN_LAYER_NUM; m++)
	{
		for(j = 0; j < INPUT_NUM; j++)
		{
			printf("w1[%d][%d]:%f\n",j,m,w1[j][m]);
		}
		printf("b1[%d]:%f\n",m,b1[m]);
	}
	for(m = 0; m < HIDDEN_LAYER_NUM; m++)
	{
		printf("w2[%d]:%f\n",m,w2[m]);
	}
	printf("b2:%f\n",b2);
}
